# -DeepSeek-R1-RAG-
［目的/意义］ 先秦文化元典是中华文明的源头文献，对其进行知识组织与智能应用，可以为建设中华民族现代文明提供历史依据和价值判断，增强国家文化软实力。本研究旨在基于检索增强生成（RAG）技术的先秦文化元典智能问答系统，推动相关知识的智能化应用与传承。
### 1：论文在解决什么问题?（why)
这篇论文以Deepseek+RAG为基底来帮助大众理解先秦文化智能问答研究

### 2：这件事为什么值得做？（Motivation）
1：先秦是中华文明源头的基础文献，是中华民国文化基因之渊薮
2：大模型的‘爆发期’发展给了这个团队一个机会
3：Deepseek+RAG的的组合让准确的得到了大幅度的提高

### 3：作者用了什么方法？（What / How）
1：利用 BERT实现自动句读
2：CRFs机器学习模型
3：Bert-BiLSTM-MHA-CRF 模型
4：Deepseek+RAG(GraphRAG、NaiveRAG、LightRAG、HybridRAG)
<img width="1196" height="1303" alt="image" src="https://github.com/user-attachments/assets/e07ac603-1d21-4215-883c-2dca13ab525c" />

<img width="974" height="1157" alt="image" src="https://github.com/user-attachments/assets/0ff223eb-e676-4ddf-900e-731c8ed4591f" />

### 4：数据从哪来？（Data）
① 先秦经典文本语料库
② 知识图谱知识源数据
③ 检索增强所用外部资源
- _知识来源是真实的古典文本_（不是泛互联网或 ChatGPT 知识）
    
- _RAG 不是凭空生成，而是基于检索证据生成答案_


### 5：实验怎么证明它有效？（Experiment）

### ① DeepSeek-R1 抽取质量评估

- 使用 DeepSeek-R1 对原始古籍文本抽取三元组；
    
- 通过“覆盖率 + 质量”指标验证三元组是否准确且对问答有贡献。
    
 **证明点：**

> 抽取的知识三元组能够覆盖关键知识，并用于构建知识图谱。

###  ② 多种 RAG 机制对问答效果的对比

论文评估了 **4 种 RAG 方法**：

|方法|主要特点|
|---|---|
|**GraphRAG**|利用知识图谱结构进行检索|
|**NaiveRAG**|传统检索增强|
|**LightRAG**|轻量级检索生成|
|**HybridRAG**|混合多种检索机制|
### ③ 典型问题类型评估

论文根据问题类型设计输出准确性指标：

例如：

- **考证溯源类**问题更适合增强知识图谱的方法（如 GraphRAG）；
    
- **事实问答类**问题 NaiveRAG 表现更好。
总结：不同 RAG 技术有其适用场景，系统整体比纯 LLM 能显著提升答案质量和可解释性


### 6：这篇论文的「优点 & 局限」？（Strength & Limitation）

优点：
**1 ：面向古典文化语境提出专门方案**
2： 实验对比全面
3：更强的可解释性

局限：
1：数据规模可能偏小
2：缺乏统一 benchmark
3：DeepSeek-R1 本身特点引发的一些局限

### 7：对我有什么用？（Your Takeaway）
1：让我知道了更多RAG工具库
2：知道了先秦的历史文化
3：Deepseek+RAG这种组合相较于其他的大模型的优势
4：实验数据让我觉得是最充足的一篇
